{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "91e5629c-dade-4b8f-8a39-07aa641484c4",
      "metadata": {
        "id": "91e5629c-dade-4b8f-8a39-07aa641484c4"
      },
      "source": [
        "**MIMIC-IV Feature extraction from postgresql**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d01e6ea6-053d-4b30-ad31-b8fe92873e1f",
      "metadata": {
        "tags": [],
        "id": "d01e6ea6-053d-4b30-ad31-b8fe92873e1f"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e39599f8-d873-47c4-9b2b-a3b1d8d0d5a6",
      "metadata": {
        "id": "e39599f8-d873-47c4-9b2b-a3b1d8d0d5a6"
      },
      "outputs": [],
      "source": [
        "!pip install psycopg2-binary --quiet\n",
        "!pip install --upgrade jupyterlab jupyterlab-git --quiet\n",
        "#!pip install pydantic --quiet\n",
        "!pip install tqdm --quiet\n",
        "!pip install scikit-learn --quiet\n",
        "!pip install seaborn --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe3a40e3-43a3-428e-a8a2-1150a9df14a0",
      "metadata": {
        "id": "fe3a40e3-43a3-428e-a8a2-1150a9df14a0"
      },
      "outputs": [],
      "source": [
        "import psycopg2 as pg\n",
        "import pandas as pd\n",
        "import pandas.io.sql as psql"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d747e6-a3e4-4bd2-b7d2-5ca009a0f198",
      "metadata": {
        "id": "f9d747e6-a3e4-4bd2-b7d2-5ca009a0f198"
      },
      "outputs": [],
      "source": [
        "postgres_ip = 'CHANGE_IT'\n",
        "db = 'mimiciv'\n",
        "schema = 'mimiciv_hosp'\n",
        "port = 5432 # default\n",
        "username = 'CHANGE_IT'\n",
        "password = 'CHANGE_IT'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a5ab00b-aacb-431b-8784-bca0170c6c07",
      "metadata": {
        "id": "2a5ab00b-aacb-431b-8784-bca0170c6c07"
      },
      "outputs": [],
      "source": [
        "connection = pg.connect(f\"host={postgres_ip} dbname={db} user={username} password={password}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bedc7e5-f095-4a9c-a561-afd207b54c89",
      "metadata": {
        "tags": [],
        "id": "7bedc7e5-f095-4a9c-a561-afd207b54c89"
      },
      "source": [
        "# Read the data from postgresql\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13e55032-9591-49dc-b0c6-703dcd8b75cb",
      "metadata": {
        "id": "13e55032-9591-49dc-b0c6-703dcd8b75cb"
      },
      "outputs": [],
      "source": [
        "sql_query = f\"\"\"\n",
        "                WITH diagnoses AS (\n",
        "                  SELECT \n",
        "                    dx.*, \n",
        "                    di.long_title \n",
        "                  FROM \n",
        "                    {schema}.diagnoses_icd dx \n",
        "                    INNER JOIN {schema}.d_icd_diagnoses di ON dx.icd_code = di.icd_code \n",
        "                  WHERE dx.icd_version = 10 AND di.icd_version = dx.icd_version\n",
        "                ), \n",
        "                diagnoses_with_year AS (\n",
        "                  SELECT \n",
        "                    date_part('year', admittime) event_year, \n",
        "                    a.hadm_id, \n",
        "                    a.subject_id, \n",
        "                    d.icd_code, \n",
        "                    d.icd_version, \n",
        "                    d.long_title, \n",
        "                    a.admission_type, \n",
        "                    d.seq_num \n",
        "                  FROM \n",
        "                    diagnoses d \n",
        "                    INNER JOIN {schema}.admissions a ON d.hadm_id = a.hadm_id\n",
        "                ), \n",
        "                admission_with_age AS (\n",
        "                  SELECT \n",
        "                    ad.subject_id, \n",
        "                    ad.hadm_id, \n",
        "                    ad.admittime, \n",
        "                    ad.admission_type, \n",
        "                    EXTRACT(\n",
        "                      YEAR \n",
        "                      FROM \n",
        "                        ad.admittime\n",
        "                    ) - pa.anchor_year + pa.anchor_age AS age \n",
        "                  FROM \n",
        "                    {schema}.admissions ad \n",
        "                    INNER JOIN {schema}.patients pa ON ad.subject_id = pa.subject_id\n",
        "                ), \n",
        "                final_feature_extraction AS (\n",
        "                  SELECT \n",
        "                    a.subject_id, \n",
        "                    a.hadm_id, \n",
        "                    a.age, \n",
        "                    a.admittime, \n",
        "                    a.admission_type, \n",
        "                    d.event_year, \n",
        "                    d.icd_code, \n",
        "                    d.icd_version, \n",
        "                    d.long_title, \n",
        "                    d.seq_num \n",
        "                  FROM \n",
        "                    diagnoses_with_year d \n",
        "                    INNER JOIN admission_with_age a ON d.hadm_id = a.hadm_id\n",
        "                ) \n",
        "                SELECT \n",
        "                  * \n",
        "                FROM \n",
        "                  final_feature_extraction\n",
        "                ORDER BY \n",
        "                  admittime ASC \n",
        "                \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "549b75d0-cf65-48cc-9efb-87b4933ada78",
      "metadata": {
        "id": "549b75d0-cf65-48cc-9efb-87b4933ada78"
      },
      "outputs": [],
      "source": [
        "diagnosis_df = psql.read_sql(sql_query, connection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02b53751-8f1a-4495-96b4-5774fa3c76ec",
      "metadata": {
        "id": "02b53751-8f1a-4495-96b4-5774fa3c76ec",
        "outputId": "52d42044-dd04-4dbd-c1b6-72572dd6b04e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "103.0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diagnosis_df['age'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea4d636-9204-43f4-82a7-ac92f2ea8db1",
      "metadata": {
        "id": "5ea4d636-9204-43f4-82a7-ac92f2ea8db1",
        "outputId": "ed2e5c95-eabc-42ae-ba91-61624f1b796e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2212.0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diagnosis_df['event_year'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0d51acc-5524-410b-ab09-9ae65be05666",
      "metadata": {
        "id": "e0d51acc-5524-410b-ab09-9ae65be05666",
        "outputId": "142571e9-47e2-4f44-eb82-71783786a761"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17009"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(set(diagnosis_df['icd_code']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f09996b-02cd-4d5a-8f2a-ddd5dd85b7d9",
      "metadata": {
        "id": "7f09996b-02cd-4d5a-8f2a-ddd5dd85b7d9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# Download the CSV file from the URL and save it to a local file\n",
        "icd_aggegator_df = pd.read_csv('ccs_dx_icd10cm_2018_1.csv')\n",
        "icd_aggegator_df.columns = icd_aggegator_df.columns.str.replace(\"'\", \"\")\n",
        "icd_aggegator_df = icd_aggegator_df.applymap(lambda x: x.replace(\"'\", \"\"))\n",
        "\n",
        "# Create a dictionary mapping ICD-10-CM codes to CCS categories\n",
        "icd10_ccs_mapping = icd_aggegator_df.set_index('ICD-10-CM CODE')['CCS CATEGORY'].to_dict()\n",
        "temp_icd_codes = set(diagnosis_df['icd_code']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0189aa69-3661-41fb-9d2e-fbd262bda0e9",
      "metadata": {
        "id": "0189aa69-3661-41fb-9d2e-fbd262bda0e9"
      },
      "outputs": [],
      "source": [
        "def icd_codes_preprocessing(icd_code: str, with_icd10_codes_aggregation=False):\n",
        "    icd_code = icd_code.strip()\n",
        "    if with_icd10_codes_aggregation:\n",
        "        icd_code = icd10_ccs_mapping[icd_code] if icd_code in icd10_ccs_mapping else icd_code\n",
        "    return icd_code\n",
        "\n",
        "diagnosis_df['icd_code'] = diagnosis_df['icd_code'].apply(lambda icd_code: icd_codes_preprocessing(icd_code, with_icd10_codes_aggregation=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d9e73f2-8573-49b1-91f2-3502034c9f3a",
      "metadata": {
        "id": "8d9e73f2-8573-49b1-91f2-3502034c9f3a"
      },
      "outputs": [],
      "source": [
        "counter = 0\n",
        "missing_elements = []\n",
        "\n",
        "for element in temp_icd_codes:\n",
        "    element = element.strip()\n",
        "    if element not in icd10_ccs_mapping:\n",
        "        counter += 1\n",
        "        missing_elements.append(element)\n",
        "print(f'Number of elements in the set that are not in the dictionary: {counter}')\n",
        "missing_elements[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bff4560c-d662-45c0-85f2-2679f9a39ba5",
      "metadata": {
        "id": "bff4560c-d662-45c0-85f2-2679f9a39ba5",
        "outputId": "757abeba-0bcd-4329-9c23-32ce5d025b83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of unique patients is: 84453\n"
          ]
        }
      ],
      "source": [
        "print(f'The number of unique patients is: {len(set(diagnosis_df.subject_id))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e4d38ad-f6d3-4c9f-b03f-69ef81869e41",
      "metadata": {
        "id": "8e4d38ad-f6d3-4c9f-b03f-69ef81869e41",
        "outputId": "13e9962b-16b9-4fab-8b32-c566cf712b88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of unique diagnosis codes after aggregation is: 416\n"
          ]
        }
      ],
      "source": [
        "print(f'The number of unique diagnosis codes after aggregation is: {len(set(diagnosis_df.icd_code))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32cc4c88-ceeb-42a7-8ade-0c6f4becc289",
      "metadata": {
        "id": "32cc4c88-ceeb-42a7-8ade-0c6f4becc289"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.path.exists('data/icd10'):\n",
        "    os.makedirs('data/icd10')\n",
        "\n",
        "diagnosis_df.to_csv(f'data/icd10/mimic_iv_icd10_features_with_aggregations.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bc782de-fa8f-42d1-ad3f-6db9c0e3b1a0",
      "metadata": {
        "tags": [],
        "id": "9bc782de-fa8f-42d1-ad3f-6db9c0e3b1a0"
      },
      "source": [
        "# Convert to `BEHRT` input format"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fd71ddf-6a4b-426c-aa16-feea348651d4",
      "metadata": {
        "id": "2fd71ddf-6a4b-426c-aa16-feea348651d4"
      },
      "source": [
        "`BEHRT` example `code` input: `['disease1', 'SEP', 'medication1', 'medication2', 'disease2', 'SEP', 'disease3', 'SEP', 'disease4', 'medication1', 'SEP']`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68d16dac-d4c5-4665-a6e2-1cafa5cef38b",
      "metadata": {
        "id": "68d16dac-d4c5-4665-a6e2-1cafa5cef38b"
      },
      "source": [
        "## Create the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a9f467c-ff60-438b-bdf9-208701f496cf",
      "metadata": {
        "id": "3a9f467c-ff60-438b-bdf9-208701f496cf"
      },
      "outputs": [],
      "source": [
        "def build_behrt_visit_codes(df: pd.DataFrame, hadm_id: int, visit_separator: str):\n",
        "    visit_df = df[df['hadm_id'] == hadm_id]\n",
        "    #visit_df = visit_df.sort_values(by=['seq_num'])\n",
        "    concept_ids, ages, years =  list(visit_df['icd_code']), list(visit_df['age']), list(visit_df['event_year'])\n",
        "    concept_ids.append(visit_separator)\n",
        "    ages.append(ages[-1])\n",
        "    years.append(years[-1])\n",
        "    return concept_ids, ages, years"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb8ef6c7-c07b-432b-a71e-a920e22686b2",
      "metadata": {
        "id": "cb8ef6c7-c07b-432b-a71e-a920e22686b2",
        "outputId": "39b65480-45d7-4f02-c1dc-4c69e75cd89b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(['144', '140', '10', '140', '135', '176', '2617', 'SEP'], [52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0], [2147.0, 2147.0, 2147.0, 2147.0, 2147.0, 2147.0, 2147.0, 2147.0])\n"
          ]
        }
      ],
      "source": [
        "print(build_behrt_visit_codes(diagnosis_df, hadm_id=tuple(diagnosis_df['hadm_id'].sample())[0], visit_separator='SEP'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bd487eb-c72f-4311-803c-c85e1b63c2db",
      "metadata": {
        "id": "7bd487eb-c72f-4311-803c-c85e1b63c2db"
      },
      "outputs": [],
      "source": [
        "def build_behrt_codes_for_person(person_id: int, visit_separator: str):\n",
        "    person_codes = []\n",
        "    person_ages = []\n",
        "    person_years = []\n",
        "    \n",
        "    person_visit_hadm_ids = list(dict.fromkeys((diagnosis_df[diagnosis_df['subject_id'] == person_id]['hadm_id'])))\n",
        "    for person_visit_id in person_visit_hadm_ids:\n",
        "        visit_codes, visit_ages, visit_years = build_behrt_visit_codes(df=diagnosis_df, hadm_id=person_visit_id, visit_separator=visit_separator)\n",
        "        person_codes.extend(visit_codes)\n",
        "        person_ages.extend(visit_ages)\n",
        "        person_years.extend(visit_years)\n",
        "    return person_codes, person_ages, person_years"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b5181f3-ecdb-447c-bed1-91ec88b24d84",
      "metadata": {
        "id": "2b5181f3-ecdb-447c-bed1-91ec88b24d84",
        "outputId": "0f9a3811-e08b-4226-907c-da8077a7920a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(['2621', '53', '661', '657', '48', '138', '257', '113', '113', '113', '50', '165', '232', '2611', '136', '98', '3', 'SEP', '99', '96', '257', '2621', '2611', '131', '236', '50', '108', '62', '661', '101', '157', '60', '113', '197', '3', '100', '53', 'SEP', '661', '101', '101', '99', '114', '108', '113', '50', 'SEP'], [67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0], [2159.0, 2159.0, 2159.0, 2159.0, 2159.0, 2159.0, 2159.0, 2159.0, 2159.0, 2159.0, 2159.0, 2159.0, 2159.0, 2159.0, 2159.0, 2159.0, 2159.0, 2159.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0, 2161.0])\n"
          ]
        }
      ],
      "source": [
        "print(build_behrt_codes_for_person(person_id=tuple(diagnosis_df['subject_id'].sample())[0], visit_separator='SEP'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0ce343a-979b-40dd-8955-fb1ab8e0ae58",
      "metadata": {
        "id": "d0ce343a-979b-40dd-8955-fb1ab8e0ae58"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def build_behrt_codes_dataset(df: pd.DataFrame, visit_separator: str):\n",
        "    person_ids = list(dict.fromkeys(df['subject_id']))\n",
        "    ds_rows = []\n",
        "    for person_id in tqdm(person_ids, desc = 'building ds from patients Progress Bar', disable=True):\n",
        "        person_condition_codes, person_condition_ages, person_condition_years = build_behrt_codes_for_person(person_id, visit_separator)\n",
        "        person_data = {'person_id': person_id, 'code': person_condition_codes, 'age': person_condition_ages, 'year': person_condition_years}\n",
        "        ds_rows.append(person_data)\n",
        "    return pd.DataFrame(ds_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d085a5-1b8b-4ea7-9dfe-03a1ba833e64",
      "metadata": {
        "id": "f9d085a5-1b8b-4ea7-9dfe-03a1ba833e64",
        "outputId": "e2ffd7b7-4105-40c3-b30b-be7a0bd0b826"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "building ds from patients Progress Bar: 100%|██████████| 84453/84453 [19:39<00:00, 71.60it/s]\n"
          ]
        }
      ],
      "source": [
        "input_dataset = build_behrt_codes_dataset(diagnosis_df, visit_separator='SEP')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cda8e43-5a28-4d42-a3c0-57c273d6d049",
      "metadata": {
        "id": "4cda8e43-5a28-4d42-a3c0-57c273d6d049"
      },
      "outputs": [],
      "source": [
        "input_dataset.to_csv('data/icd10/mimic_iv_behrt_with_aggregations_ds.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c75cfee7-ec18-4e69-bb26-705d1f95745d",
      "metadata": {
        "id": "c75cfee7-ec18-4e69-bb26-705d1f95745d"
      },
      "outputs": [],
      "source": [
        "# train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_dataset_train_df, input_dataset_test_df = train_test_split(input_dataset, test_size=0.2)\n",
        "input_dataset_train_df.to_csv(\"data/icd10/mimic_iv_behrt_with_aggregations_train_ds.csv\", index=False)\n",
        "input_dataset_test_df.to_csv(\"data/icd10/mimic_iv_behrt_with_aggregations_test_ds.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ea6db5d-55db-4c97-9e62-59c713005a33",
      "metadata": {
        "id": "8ea6db5d-55db-4c97-9e62-59c713005a33"
      },
      "source": [
        "## Build `token2index` (`token2idx.json` file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75f2cfbe-33af-4e50-abeb-141974a9ac5d",
      "metadata": {
        "id": "75f2cfbe-33af-4e50-abeb-141974a9ac5d"
      },
      "outputs": [],
      "source": [
        "TOKEN2INX_FILE_PATH = '../../BEHRT/my_data/mimic_iv_icd10_with_aggregations_token2idx.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6bc35cc-b701-454e-9921-1d19c770c582",
      "metadata": {
        "id": "b6bc35cc-b701-454e-9921-1d19c770c582"
      },
      "outputs": [],
      "source": [
        "from typing import List \n",
        "\n",
        "def get_all_codes(df: pd.DataFrame, codes_to_ignore: List[str]) -> List[str]:\n",
        "    codes = []\n",
        "    for df_list_codes in list(df['code']):\n",
        "        codes.extend(df_list_codes)\n",
        "    return list(set(codes) - set(codes_to_ignore))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e6bba73-6836-4032-987a-7cdf9a96f6d8",
      "metadata": {
        "id": "2e6bba73-6836-4032-987a-7cdf9a96f6d8",
        "outputId": "9cf93d2b-e3af-4ec5-f6bc-01cd3d54e514"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of unique codes: 412\n"
          ]
        }
      ],
      "source": [
        "print(f'number of unique codes: {len(get_all_codes(df=input_dataset, codes_to_ignore=[])) - 5}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37aad331-aae5-464d-8298-4214c839b1aa",
      "metadata": {
        "id": "37aad331-aae5-464d-8298-4214c839b1aa"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "\n",
        "from typing import List \n",
        "\n",
        "def get_all_codes(df: pd.DataFrame, codes_to_ignore: List[str]) -> List[str]:\n",
        "    codes = []\n",
        "    for df_list_codes in list(df['code']):\n",
        "        codes.extend(df_list_codes)\n",
        "    return list(set(codes) - set(codes_to_ignore))\n",
        "\n",
        "def get_bert_tokens() -> Dict[str, int]:\n",
        "    return {\n",
        "      \"PAD\": 0,\n",
        "      \"UNK\": 1,\n",
        "      \"SEP\": 2,\n",
        "      \"CLS\": 3,\n",
        "      \"MASK\": 4,\n",
        "    }\n",
        "    \n",
        "def build_token2index_dict(df: pd.DataFrame) -> Dict[str, int]:\n",
        "    token2inx_dict = get_bert_tokens()\n",
        "    next_index = max(token2inx_dict.values()) + 1\n",
        "    \n",
        "    codes = get_all_codes(df= df, codes_to_ignore=token2inx_dict.keys())\n",
        "    for code in codes:\n",
        "        token2inx_dict[str(code)] = next_index\n",
        "        next_index += 1\n",
        "    return token2inx_dict\n",
        "\n",
        "def create_token2index_file(df: pd.DataFrame, output_file_path: str):\n",
        "    token2inx_dict = build_token2index_dict(df= df)\n",
        "    with open(output_file_path, 'w') as f:\n",
        "        json.dump(token2inx_dict, f)\n",
        "        print(f'token2inx was created, path={output_file_path}')\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0810af5e-cc14-49e8-bb7a-7d1b684de6d7",
      "metadata": {
        "id": "0810af5e-cc14-49e8-bb7a-7d1b684de6d7"
      },
      "outputs": [],
      "source": [
        "create_token2index_file(df= input_dataset, output_file_path=TOKEN2INX_FILE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30ae5fc7-7e60-4d45-9c16-5a8090d49878",
      "metadata": {
        "id": "30ae5fc7-7e60-4d45-9c16-5a8090d49878"
      },
      "outputs": [],
      "source": [
        "!python ../../BEHRT/preprocess/bert_vocab_builder.py {TOKEN2INX_FILE_PATH} mimic_iv_icd10_with_aggregations_vocab.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10b53748-80a0-4bc8-8727-bbdf3849fc23",
      "metadata": {
        "tags": [],
        "id": "10b53748-80a0-4bc8-8727-bbdf3849fc23"
      },
      "source": [
        "## Build BEHRT downstream task dataset. \n",
        "`Next visit prediction`: for each patient, we randomally choose `j` index (where `3<j<number_of_visits`).\n",
        "\n",
        "Then we train on the first `j` visits, and test on `j+1` visit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ebcac29-3c5e-42bf-9751-11468f079bee",
      "metadata": {
        "id": "1ebcac29-3c5e-42bf-9751-11468f079bee"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict\n",
        "from random import randrange\n",
        "\n",
        "\n",
        "def split_list(list_to_split: List, separator: str):\n",
        "    list_after_split = []\n",
        "    current_list = []\n",
        "    for element in list_to_split:\n",
        "        current_list.append(element)\n",
        "        if element == separator:\n",
        "            list_after_split.append(current_list)\n",
        "            current_list = []\n",
        "    return list_after_split\n",
        "\n",
        "def split_visits(codes: List, ages: List, years: List, visit_index: int, separator: str):\n",
        "    codes_after_split = split_list(list_to_split=codes, separator=separator)\n",
        "    train_codes, test_codes = codes_after_split[:visit_index + 1], codes_after_split[visit_index + 1]\n",
        "    train_codes = [item for sublist in train_codes for item in sublist]\n",
        "    \n",
        "    #train_codes_num = sum([len(visit_codes) for visit_codes in train_codes])\n",
        "    train_codes_num = len(train_codes)\n",
        "    test_codes_num = len(test_codes) # test_codes is not a nested list, because it contains only one visit details.\n",
        "\n",
        "    train_ages, test_ages = ages[:train_codes_num], ages[train_codes_num:train_codes_num + test_codes_num]\n",
        "    train_years, test_years = years[:train_codes_num], ages[train_codes_num:train_codes_num + test_codes_num]\n",
        "    return {\n",
        "        'train_codes': train_codes,\n",
        "        'test_codes': test_codes, \n",
        "        'train_ages': train_ages, \n",
        "        'test_ages': test_ages, \n",
        "        'train_years': train_years,\n",
        "        'test_years': test_years\n",
        "    } \n",
        "\n",
        "def build_next_visit_for_person(df: pd.DataFrame, min_visit_num: int, person_id: int, visit_separator: str) -> Dict[str, List]:\n",
        "    person_df = df[df['person_id'] == person_id]\n",
        "    codes, ages, years =  list(person_df['code'])[0], list(person_df['age'])[0], list(person_df['year'])[0]\n",
        "    number_of_visits = codes.count(visit_separator)\n",
        "    j = randrange(start=min_visit_num - 1, stop=number_of_visits - 1, step=1) # another -1 for stop criteria because we need to test on the next visit.\n",
        "    return split_visits(codes, ages, years, visit_index=j, separator='SEP')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6acd72b3-8031-4580-b56d-bba2e8dbb423",
      "metadata": {
        "id": "6acd72b3-8031-4580-b56d-bba2e8dbb423"
      },
      "outputs": [],
      "source": [
        "print(build_next_visit_for_person(input_dataset, min_visit_num=1, person_id=10101340, visit_separator='SEP'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02f8093d-6db8-4b71-8277-3cba81cd4858",
      "metadata": {
        "id": "02f8093d-6db8-4b71-8277-3cba81cd4858"
      },
      "outputs": [],
      "source": [
        "def build_next_visit_ds(input_dataset: pd.DataFrame, min_visit_num: int, visit_separator: str) -> pd.DataFrame:\n",
        "    person_ids = list(dict.fromkeys(input_dataset['person_id']))\n",
        "    ds_rows = []\n",
        "    for person_id in tqdm(person_ids, desc = 'building next visit dataset Progress Bar'):\n",
        "        person_df = input_dataset[input_dataset['person_id'] == person_id]\n",
        "        codes =  list(person_df['code'])[0]\n",
        "        num_of_visits = codes.count(visit_separator)\n",
        "        if num_of_visits > min_visit_num:\n",
        "            person_visits_dict = build_next_visit_for_person(df=input_dataset, min_visit_num=min_visit_num,\n",
        "                                                       person_id=person_id, visit_separator=visit_separator)\n",
        "            person_visits_dict['person_id'] = person_id\n",
        "            ds_rows.append(person_visits_dict)\n",
        "    next_visit_ds = pd.DataFrame(ds_rows)\n",
        "    next_visit_ds = next_visit_ds[['train_codes', 'train_ages', 'person_id', 'test_codes']]\n",
        "    next_visit_ds = next_visit_ds.rename(columns={'train_codes': 'code', 'train_ages': 'age', 'test_codes': 'label', 'person_id': 'patid'})\n",
        "    return next_visit_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d22bdb7b-66b5-4562-a4b0-76e5b423f837",
      "metadata": {
        "id": "d22bdb7b-66b5-4562-a4b0-76e5b423f837"
      },
      "source": [
        "**Questions**\n",
        "1. I saw rows with the same train/test codes. Does that make sense?\n",
        "2. we don't have too much data here, especially for `min_visit_num=3`. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3621c62f-b3c8-40f2-854f-4ae1402c7364",
      "metadata": {
        "id": "3621c62f-b3c8-40f2-854f-4ae1402c7364"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_dataset_train_df = pd.read_csv(\"data/icd10/mimic_iv_behrt_with_aggregations_train_ds.csv\")\n",
        "input_dataset_test_df = pd.read_csv(\"data/icd10/mimic_iv_behrt_with_aggregations_test_ds.csv\")\n",
        "for df in (input_dataset_train_df, input_dataset_test_df):\n",
        "    for column_name in ('code', 'age', 'year'):\n",
        "        df[column_name] = df[column_name].apply(lambda x: eval(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "869df933-d210-49d5-9a0d-0fdc60ffd305",
      "metadata": {
        "id": "869df933-d210-49d5-9a0d-0fdc60ffd305",
        "outputId": "8acf7279-d656-4d57-f22f-cfb79074e1f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "building next visit dataset Progress Bar: 100%|██████████| 67562/67562 [00:39<00:00, 1716.31it/s]\n",
            "building next visit dataset Progress Bar: 100%|██████████| 16891/16891 [00:08<00:00, 2054.78it/s]\n"
          ]
        }
      ],
      "source": [
        "train_next_visit_df = build_next_visit_ds(input_dataset_train_df, min_visit_num=1, visit_separator='SEP')\n",
        "test_next_visit_df = build_next_visit_ds(input_dataset_test_df, min_visit_num=1, visit_separator='SEP')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a67a90c2-3d80-4703-92a1-91e41e46a698",
      "metadata": {
        "id": "a67a90c2-3d80-4703-92a1-91e41e46a698",
        "outputId": "ca11c97a-5590-4fb0-d069-7dc1644e3dac"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>age</th>\n",
              "      <th>patid</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2515</th>\n",
              "      <td>[59, 89, 108, 53, 259, 25, 101, 55, 213, 62, 1...</td>\n",
              "      <td>[80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80....</td>\n",
              "      <td>14065267</td>\n",
              "      <td>[158, 48, 155, 99, 108, 157, 50, 257, 50, 204,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   code  \\\n",
              "2515  [59, 89, 108, 53, 259, 25, 101, 55, 213, 62, 1...   \n",
              "\n",
              "                                                    age     patid  \\\n",
              "2515  [80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80....  14065267   \n",
              "\n",
              "                                                  label  \n",
              "2515  [158, 48, 155, 99, 108, 157, 50, 257, 50, 204,...  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_next_visit_df.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cb5eb78-830d-419a-a244-b57a1c05d751",
      "metadata": {
        "id": "1cb5eb78-830d-419a-a244-b57a1c05d751",
        "outputId": "d585609c-38cf-400b-b501-2c63e76082cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6161"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_next_visit_df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff7b9d37-49b1-4acd-a2e5-61f8f8416e23",
      "metadata": {
        "tags": [],
        "id": "ff7b9d37-49b1-4acd-a2e5-61f8f8416e23"
      },
      "outputs": [],
      "source": [
        "train_next_visit_df.to_csv('data/icd10/train_mimic_iv_behrt_with_aggregations_next_visit_ds.csv')\n",
        "test_next_visit_df.to_csv('data/icd10/test_mimic_iv_behrt_with_aggregations_next_visit_ds.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c206872f-2828-4799-a900-ff6824bd8384",
      "metadata": {
        "id": "c206872f-2828-4799-a900-ff6824bd8384"
      },
      "source": [
        "# Split the data to multi-center "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9059574-98a3-4cb4-a1a3-9051aa389229",
      "metadata": {
        "id": "b9059574-98a3-4cb4-a1a3-9051aa389229"
      },
      "outputs": [],
      "source": [
        "#diagnosis_df = pd.read_csv('data/mimic_iv_icd10_features_with_aggregations.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e615ea02-37f9-40b2-9d9e-736051a3dd9c",
      "metadata": {
        "id": "e615ea02-37f9-40b2-9d9e-736051a3dd9c"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_data_to_centers(df: pd.DataFrame, group_by_key: str, output_dir: str):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    \n",
        "    # no-need for train/test split again.\n",
        "    #diagnosis_df_train, diagnosis_df_test = train_test_split(diagnosis_df, test_size=test_size, random_state=42)\n",
        "    #diagnosis_df_test.to_csv(f'{output_dir}/test.csv')\n",
        "\n",
        "    gb = df.groupby(group_by_key)   \n",
        "    groups = dict(list(gb))\n",
        "    for group_key, group_df in tqdm(groups.items(), desc=\"split data to centers\"):\n",
        "        group_key = group_key.replace('/', '-') # something we have / in the data, for example Hematology/Oncology.\n",
        "        print(f'group_key={group_key}')\n",
        "        df_output_path = f'{output_dir}/{group_key}.csv'\n",
        "        group_df.to_csv(df_output_path)\n",
        "    print('done to split the data to centers.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10b8cd09-489f-4c6a-a624-b321c3f12f42",
      "metadata": {
        "id": "10b8cd09-489f-4c6a-a624-b321c3f12f42"
      },
      "source": [
        "## Split `MLM` training data by `careunit`"
      ]
    },
    {
      "cell_type": "raw",
      "id": "0a1b6a3c-229e-4852-a39e-84af03231d37",
      "metadata": {
        "id": "0a1b6a3c-229e-4852-a39e-84af03231d37"
      },
      "source": [
        "Each patient may have many transfers for the same hadm_id. \n",
        "Therefore, we will consider two options for aggregation:\n",
        "    1. Take the row with the first intime\n",
        "    2. Take the row with the highest stay_time (outtime - intime). notice: outtime not always present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd96ad61-e6e8-42d5-b3df-e648c99f7605",
      "metadata": {
        "id": "dd96ad61-e6e8-42d5-b3df-e648c99f7605"
      },
      "outputs": [],
      "source": [
        "transfers_sql_query = f\"\"\"\n",
        "        SELECT subject_id,\n",
        "               hadm_id,\n",
        "               transfer_id,\n",
        "               careunit,\n",
        "               intime,\n",
        "               outtime,\n",
        "               Extract(epoch FROM ( outtime - intime )) stay_time\n",
        "        FROM   mimiciv_hosp.transfers;\n",
        "\n",
        "    \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5533e1bf-ed36-4867-8038-81831a4b2618",
      "metadata": {
        "id": "5533e1bf-ed36-4867-8038-81831a4b2618"
      },
      "outputs": [],
      "source": [
        "transfers_df = psql.read_sql(transfers_sql_query, connection).dropna(subset=['hadm_id'])\n",
        "transfers_df['hadm_id'] = transfers_df['hadm_id'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1acce233-d6e5-440b-8411-67045aa800c2",
      "metadata": {
        "id": "1acce233-d6e5-440b-8411-67045aa800c2"
      },
      "outputs": [],
      "source": [
        "def split_by_max_stay_time(transfers_df: pd.DataFrame, behrt_train_df: pd.DataFrame, group_by_key: str, output_dir: str):\n",
        "    df = transfers_df.loc[transfers_df.groupby(by=['subject_id']).stay_time.idxmax()]\n",
        "    transfers_with_behrt_df = df.merge(behrt_train_df, left_on='subject_id', right_on='person_id', how='inner', suffixes=('', '_drop'))\n",
        "    ids = list(transfers_with_behrt_df['subject_id'])\n",
        "    if len(ids) == len(set(ids)):\n",
        "        print(\"There are no repeated elements in the list.\")\n",
        "    else:\n",
        "        print(\"There are repeated elements in the list.\")\n",
        "\n",
        "    split_data_to_centers(df=transfers_with_behrt_df, group_by_key=group_by_key,\n",
        "                          output_dir=output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed1e7a91-4be9-432c-9b49-b2039c8d9bc0",
      "metadata": {
        "id": "ed1e7a91-4be9-432c-9b49-b2039c8d9bc0"
      },
      "outputs": [],
      "source": [
        "split_by_max_stay_time(transfers_df, input_dataset_train_df, group_by_key='careunit', output_dir='data/icd10-multi-center/split_by_max_stay_time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5153e2b5-2fa9-4b3c-93cc-64f074ea5f12",
      "metadata": {
        "id": "5153e2b5-2fa9-4b3c-93cc-64f074ea5f12"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import os \n",
        "import glob \n",
        "\n",
        "def centers_to_behrt_format(centers_data_dir_path: str, output_behrt_dir_data_path: str):\n",
        "    if not os.path.exists(output_behrt_dir_data_path):\n",
        "        os.makedirs(output_behrt_dir_data_path)\n",
        "\n",
        "    for center_csv_path in tqdm(glob.iglob(f'{centers_data_dir_path}/*.csv'), desc=\"centers to behrt format\"):\n",
        "        center_df = pd.read_csv(center_csv_path)\n",
        "        center_file_name = os.path.basename(center_csv_path)\n",
        "        center_behrt_dataset = build_behrt_codes_dataset(center_df, visit_separator='SEP')\n",
        "        output_ds_path = f\"{output_behrt_dir_data_path}/{center_file_name}\"\n",
        "        center_behrt_dataset.to_csv(output_ds_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e30e0305-71f3-4c87-8667-be942362d489",
      "metadata": {
        "id": "e30e0305-71f3-4c87-8667-be942362d489",
        "outputId": "c34dd8aa-7b59-4417-b0ae-91afa7f4bd59"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "centers to behrt format: 39it [16:23, 25.23s/it]\n"
          ]
        }
      ],
      "source": [
        "centers_to_behrt_format(centers_data_dir_path='data/icd10-multi-center/split_by_max_stay_time/',\n",
        "               output_behrt_dir_data_path='data/icd10-multi-center/BEHRT_format/split_by_max_stay_time')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8239c2e-b6f7-4b69-a19c-97cb90dea577",
      "metadata": {
        "tags": [],
        "id": "b8239c2e-b6f7-4b69-a19c-97cb90dea577"
      },
      "source": [
        "## Split `NextVisit` data with `behrt` format by `care_unit`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9fac4c4-f451-4349-8499-4786aea43324",
      "metadata": {
        "id": "e9fac4c4-f451-4349-8499-4786aea43324",
        "outputId": "0aad12f8-620c-42e4-81dd-af3a875ed094"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'code', 'age', 'patid', 'label'], dtype='object')"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.read_csv('data/icd10/train_mimic_iv_behrt_with_aggregations_next_visit_ds.csv').columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0be43f0-5f35-4673-8087-04ae4a510311",
      "metadata": {
        "id": "e0be43f0-5f35-4673-8087-04ae4a510311"
      },
      "outputs": [],
      "source": [
        "def split_behrt_next_visit_to_centers(behrt_next_visit_path: str, output_dir: str):\n",
        "    behrt_next_visit_df = pd.read_csv(behrt_next_visit_path)\n",
        "    # convert the lists to list, because after read_csv their type is string. \n",
        "    for column_name in ('code', 'age', 'label'):\n",
        "        behrt_next_visit_df[column_name] = behrt_next_visit_df[column_name].apply(lambda x: eval(x))\n",
        "    \n",
        "\n",
        "    df = transfers_df.loc[transfers_df.groupby(by=['subject_id']).stay_time.idxmax()]\n",
        "    transfers_with_diagnosis_df = df.merge(behrt_next_visit_df, left_on='subject_id', right_on='patid', how='inner', suffixes=('', '_drop'))\n",
        "    split_data_to_centers(df=transfers_with_diagnosis_df, group_by_key='careunit', output_dir=output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af695cd8-0cab-47a9-8301-1cbd1407ec73",
      "metadata": {
        "id": "af695cd8-0cab-47a9-8301-1cbd1407ec73"
      },
      "outputs": [],
      "source": [
        "split_behrt_next_visit_to_centers(behrt_next_visit_path='data/icd10/train_mimic_iv_behrt_with_aggregations_next_visit_ds.csv', \n",
        "                                  output_dir='data/icd10-multi-center/BEHRT_format/next_visit/split_by_max_stay_time')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4da5f99-5e4d-49f8-a9d5-2906fb886044",
      "metadata": {
        "id": "c4da5f99-5e4d-49f8-a9d5-2906fb886044"
      },
      "source": [
        "## Multi-center Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e898ec14-f404-4ea7-9422-b7b351520102",
      "metadata": {
        "id": "e898ec14-f404-4ea7-9422-b7b351520102"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import seaborn as sns \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_centers_statistics(dir_path: str, title_split_name: str):\n",
        "    center_name_to_size_dict = {}\n",
        "    \n",
        "    for center_csv_path in glob.iglob(f'{dir_path}/*.csv'):\n",
        "        df = pd.read_csv(center_csv_path)\n",
        "        center_name_to_size_dict[os.path.basename(center_csv_path).replace('.csv', '')] = df.shape[0]\n",
        "        \n",
        "    print(f'The number of centers is={len(center_name_to_size_dict)}')\n",
        "    print(f'The names of the centers: {center_name_to_size_dict.keys()}')\n",
        "    d = pd.DataFrame(center_name_to_size_dict.items(), columns=['name', 'count'])\n",
        "    d = d.sort_values(by=['count'], ascending=False).head(10).sort_values(by=['count'], ascending=True)\n",
        "    \n",
        "    sns.set(font_scale=1.2, rc={\"figure.figsize\":(7, 5)})\n",
        "    #sns.barplot(data=d, x=\"count\", y=\"name\").set_title(f'multi center by {title_split_name} split. There are {len(center_name_to_size_dict)} centers')\n",
        "    d.rename(columns={'count': 'number of patients'}, inplace=True)\n",
        "    sns.barplot(data=d, x=\"number of patients\", y=\"name\").set_title(f'multi center by {title_split_name} split')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"multi-center-analysis.pdf\", format='pdf')\n",
        "\n",
        "    \n",
        "def show_centers_statistics_logarithmic_scale(dir_path: str, title_split_name: str):\n",
        "    center_name_to_size_dict = {}\n",
        "    \n",
        "    for center_csv_path in glob.iglob(f'{dir_path}/*.csv'):\n",
        "        df = pd.read_csv(center_csv_path)\n",
        "        center_name_to_size_dict[os.path.basename(center_csv_path).replace('.csv', '')] = df.shape[0]\n",
        "        \n",
        "    print(f'The number of centers is={len(center_name_to_size_dict)}')\n",
        "    print(f'The names of the centers: {center_name_to_size_dict.keys()}')\n",
        "    d = pd.DataFrame(center_name_to_size_dict.items(), columns=['name', 'count'])\n",
        "    d = d.sort_values(by=['count'], ascending=False).sort_values(by=['count'], ascending=True)\n",
        "    \n",
        "    sns.set(font_scale=1.2, rc={\"figure.figsize\":(12, 8)})\n",
        "    d.rename(columns={'count': 'number of patients'}, inplace=True)\n",
        "    sns.barplot(data=d, x=\"number of patients\", y=\"name\", log=True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"multi-center-log-scale-analysis.pdf\", format='pdf')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "882367ff-2703-4cc4-952c-6277dd073aa8",
      "metadata": {
        "id": "882367ff-2703-4cc4-952c-6277dd073aa8"
      },
      "outputs": [],
      "source": [
        "show_centers_statistics(dir_path='data/icd10-multi-center/split_by_max_stay_time/', title_split_name='max stay time')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48d8610e-8469-4210-a5d2-4ff42f72f8b7",
      "metadata": {
        "id": "48d8610e-8469-4210-a5d2-4ff42f72f8b7"
      },
      "outputs": [],
      "source": [
        "show_centers_statistics(dir_path='data/icd10-multi-center/BEHRT_format/next_visit/split_by_max_stay_time/', title_split_name='next-visit, max_stay_time')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "my env",
      "language": "python",
      "name": "my_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "toc-autonumbering": true,
    "toc-showcode": true,
    "toc-showmarkdowntxt": true,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}